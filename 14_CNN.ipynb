{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp2uN3sNyYWhHjjeQS52rz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathewS424/PyTorch-Tutorial/blob/main/14_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT MNIST IMAGES - VIDEO 14**"
      ],
      "metadata": {
        "id": "qKsV6QWt3v0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "u5XelT-x34mv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert MNIST IMAGE Files into a Tensor of 4 -Dimensions(no.of images, height, width, Colorr channel)\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "pE0m8TBh4svA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "T01SBE2X5cmo",
        "outputId": "c8698968-acda-4322-9930-e558328270f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /cnn_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 33513258.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/train-images-idx3-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 2227455.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/train-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /cnn_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 10110228.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1063265.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "6Wxic42457Yv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dephvVV26Ms_",
        "outputId": "4e636046-2fe5-4ecf-9439-a69ec4139150"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B21k1eSn6QNn",
        "outputId": "c53db3bb-cfd6-425b-b7c7-9a8550b791b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TXflMurn6Pe3",
        "outputId": "81f60273-e832-49f2-85d8-cbfd73884df9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcxTQ09N6grv",
        "outputId": "f8f1aa3f-eead-4ece-a23e-8b48a9e041af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHEjdA_56iw3",
        "outputId": "e86e7355-3b15-4240-d3d2-2e76f62346fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wiy5soFk6lDH",
        "outputId": "9254a95b-4b9b-46bd-c3b6-1d19b12eb473"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zicgC3di6oLf",
        "outputId": "218e30b8-e504-40f7-b099-c9b5d52b9223"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;36mbin\u001b[0m@       cuda-keyring_1.0-1_all.deb  \u001b[01;34mhome\u001b[0m/   \u001b[01;36mlibx32\u001b[0m@                   \u001b[01;34mopt\u001b[0m/         \u001b[01;34mrun\u001b[0m/   \u001b[30;42mtmp\u001b[0m/\n",
            "\u001b[01;34mboot\u001b[0m/      \u001b[01;34mdatalab\u001b[0m/                    \u001b[01;36mlib\u001b[0m@    \u001b[01;34mmedia\u001b[0m/                    \u001b[01;34mproc\u001b[0m/        \u001b[01;36msbin\u001b[0m@  \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mcnn_data\u001b[0m/  \u001b[01;34mdev\u001b[0m/                        \u001b[01;36mlib32\u001b[0m@  \u001b[01;34mmnt\u001b[0m/                      \u001b[01;34mpython-apt\u001b[0m/  \u001b[01;34msrv\u001b[0m/   \u001b[01;34musr\u001b[0m/\n",
            "\u001b[01;34mcontent\u001b[0m/   \u001b[01;34metc\u001b[0m/                        \u001b[01;36mlib64\u001b[0m@  NGC-DL-CONTAINER-LICENSE  \u001b[01;34mroot\u001b[0m/        \u001b[01;34msys\u001b[0m/   \u001b[01;34mvar\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd cnn_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHZBiso16tUP",
        "outputId": "3b9fbc89-7920-403d-e29d-790a610459a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/cnn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuqtwtwB60Cv",
        "outputId": "d5f64a91-c91a-48f2-cf99-3c323e231d26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMNIST\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61tRNub866aP",
        "outputId": "4e2f2953-1235-4cdc-96eb-8847d24d899b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAn96zNr681-",
        "outputId": "f8eccc75-f065-48ba-f32b-8c94c4b35ecd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;36mbin\u001b[0m@       cuda-keyring_1.0-1_all.deb  \u001b[01;34mhome\u001b[0m/   \u001b[01;36mlibx32\u001b[0m@                   \u001b[01;34mopt\u001b[0m/         \u001b[01;34mrun\u001b[0m/   \u001b[30;42mtmp\u001b[0m/\n",
            "\u001b[01;34mboot\u001b[0m/      \u001b[01;34mdatalab\u001b[0m/                    \u001b[01;36mlib\u001b[0m@    \u001b[01;34mmedia\u001b[0m/                    \u001b[01;34mproc\u001b[0m/        \u001b[01;36msbin\u001b[0m@  \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mcnn_data\u001b[0m/  \u001b[01;34mdev\u001b[0m/                        \u001b[01;36mlib32\u001b[0m@  \u001b[01;34mmnt\u001b[0m/                      \u001b[01;34mpython-apt\u001b[0m/  \u001b[01;34msrv\u001b[0m/   \u001b[01;34musr\u001b[0m/\n",
            "\u001b[01;34mcontent\u001b[0m/   \u001b[01;34metc\u001b[0m/                        \u001b[01;36mlib64\u001b[0m@  NGC-DL-CONTAINER-LICENSE  \u001b[01;34mroot\u001b[0m/        \u001b[01;34msys\u001b[0m/   \u001b[01;34mvar\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pwmr7Zi6-_u",
        "outputId": "74cf32f6-6539-476e-b3b4-b4537f2f7455"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "INicl3OK7CHG",
        "outputId": "607e81c2-3932-4a0f-bf4d-17fc49433359"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONVOLUTIONAL AND POOLING LAYERS - VIDEO 15**"
      ],
      "metadata": {
        "id": "_QzG9_VUAHlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small batch size for images ..that is 10\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "AS5ijlEiAPPW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Our CNN Model\n",
        "# Describe convolutional layer and what  its doing (2 convolutional layers)\n",
        "# This is just am example in the next video we'll build out the actual model\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 =  nn.Conv2d(6, 16, 3, 1)  # we have not set padding parameters so the images becomes 26 X 26 it was 28 x 28 .\n",
        "# becaues the boundry of the MINIST images are unusefull so its skipped the data of that boundry part and become 26x26(check output of In [26]:x.shape)\n",
        "# Check Video -15 08:40"
      ],
      "metadata": {
        "id": "5aqTMrfMA84e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIST RECORD/IMAGE\n",
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "  break"
      ],
      "metadata": {
        "id": "ynHO4tZBJ3P6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "UIs_RL3VKNSa",
        "outputId": "9154eb1e-dd16-45c1-f06e-58e738e1f0c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1, 1, 28, 28)"
      ],
      "metadata": {
        "id": "xf1H9iK-KiJr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform our first convolution\n",
        "x = F.relu(conv1(x)) # Rectified Linear Unit for our activation function"
      ],
      "metadata": {
        "id": "u4EvjNBkKloT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 images, 6 is the filter\n",
        "x.shape   # How it becomes 26 x 26 anser is in In[20] or # Check Video -15 08:40"
      ],
      "metadata": {
        "id": "Kh65Q51HLEob",
        "outputId": "1b2df63e-113a-42ca-a9ad-ae5f0753369d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass through the pooling layer\n",
        "x = F.max_pool2d(x, 2, 2) #kernel of 2 and stride of 2"
      ],
      "metadata": {
        "id": "mFUdtcxUMoBL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape  # 26 / 2 = 13"
      ],
      "metadata": {
        "id": "6s934VB6NA8S",
        "outputId": "a30757cd-2268-4639-dd9c-8434f362b248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do our second Convolution\n",
        "x = F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "Mg-JFw8MNO4C"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape  #  we did not set any padding in conv2 so the img pixel was 13 x 13 reduce 2 becomes 11 x 11\n",
        "# (reduced around outside of the images)"
      ],
      "metadata": {
        "id": "zzvNAMfwNgix",
        "outputId": "4452fb42-de47-48d1-e32d-617d79a9215c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do another pooling layer\n",
        "x = F.max_pool2d(x, 2, 2)  #kernel of 2 and stride of 2"
      ],
      "metadata": {
        "id": "EumfmlClN6GC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape  # 11 / 2 = 5.5 but we have to round down, because you can't invent data to round up"
      ],
      "metadata": {
        "id": "KfgUMDR4OEXb",
        "outputId": "a29c50b5-7926-4384-eb90-3e16ff548c39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((28-2) / 2 -2) / 2  # order of reducing images from convolutional layer ,pooling layer to 5.5 pixel from 28 pixel initially"
      ],
      "metadata": {
        "id": "LOZVI3P3OpKL",
        "outputId": "9debb642-6a2b-475b-f70f-f98672ecfb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.5"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONVOLUTIONAL NEURAL NETWOORK MODEL -VIDEO - 16**"
      ],
      "metadata": {
        "id": "9TkTAC_RQWcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model class - above code together\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 1st convolutional layer\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "    # 2nd convolutional layer\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "\n",
        "    # Fully connected Layer after Conv ,pooling layers its fully connected layer check image of CNN\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)  # 120,84,10 are randoms\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X, 2, 2)  # 2x2 kernel and stride of 2\n",
        "    # Second pass\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "\n",
        "    # Re-View to flattten it out\n",
        "    X = X.view(-1, 5*5*16)  # -1 SO THAT WE CAN VARY THE BATCH SIZE\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    x = self.fc3(X)\n",
        "\n",
        "    return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "jrVWM47fQfmw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of  our model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "id": "sx0OO7RJT6b5",
        "outputId": "4b43794a-a3fb-4ae2-d9c5-4e05e024552d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # learning rate of 0.01 smaller lr ,longer its gonna take to train"
      ],
      "metadata": {
        "id": "pZSO92-wUmb5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**### Detailed Explanation of the Code Lines**\n",
        "\n",
        "I'll explain each part of the code as if you're learning it for the first time, with a focus on what each line does, why certain parameters are used, and how the numbers fit into the overall picture.\n",
        "\n",
        "#### [3] Convert MNIST IMAGE Files into a Tensor of 4-Dimensions\n",
        "\n",
        "```python\n",
        "transform = transforms.ToTensor()\n",
        "```\n",
        "\n",
        "- **What it does:** This line of code converts images into a tensor, which is a multi-dimensional array that PyTorch can process.\n",
        "- **Why it's used:** The MNIST dataset images are originally in PIL format (Python Imaging Library), and we need to convert them into tensors so they can be used in deep learning models. Tensors allow the model to perform mathematical operations on the data.\n",
        "- **4-Dimensions:** When we convert an image to a tensor, it becomes a 4D tensor of shape `(number of images, channels, height, width)`. For grayscale images like MNIST, the number of channels is 1.\n",
        "\n",
        "#### [4] Train Data\n",
        "\n",
        "```python\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)\n",
        "```\n",
        "\n",
        "- **What it does:** This line downloads the MNIST dataset and prepares it for training.\n",
        "- **Parameters:**\n",
        "  - `root='/cnn_data'`: Specifies the directory where the dataset will be stored.\n",
        "  - `train=True`: Indicates that we are downloading the training set.\n",
        "  - `download=True`: If the dataset isn't already in the specified directory, it will be downloaded.\n",
        "  - `transform=transform`: Applies the transformation (conversion to tensor) to each image in the dataset.\n",
        "  \n",
        "#### [5] Test Data\n",
        "\n",
        "```python\n",
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)\n",
        "```\n",
        "\n",
        "- **What it does:** Similar to the training data, but this line downloads the test set.\n",
        "- **Parameters:**\n",
        "  - `train=False`: This specifies that we are downloading the test set.\n",
        "\n",
        "#### [19] Create Data Loaders\n",
        "\n",
        "```python\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)\n",
        "```\n",
        "\n",
        "- **What it does:** These lines create data loaders, which are tools that help load the data in batches for training and testing.\n",
        "- **Parameters:**\n",
        "  - `batch_size=10`: Specifies that each batch will contain 10 images. Smaller batches require less memory but take longer to train.\n",
        "  - `shuffle=True`: Randomly shuffles the training data at every epoch to help the model generalize better.\n",
        "  - `shuffle=False`: The test data is not shuffled because we want consistent results when evaluating the model.\n",
        "\n",
        "#### [20] Define Convolutional Layers\n",
        "\n",
        "```python\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "```\n",
        "\n",
        "- **What it does:** These lines define two convolutional layers in the neural network.\n",
        "- **Parameters:**\n",
        "  - `1`: The number of input channels. For MNIST, this is 1 because the images are grayscale.\n",
        "  - `6` and `16`: The number of output channels (filters). Each filter will learn to detect different features in the image.\n",
        "  - `3`: The size of the convolutional filter (3x3).\n",
        "  - `1`: The stride, which indicates how the filter moves across the image. A stride of 1 means it moves 1 pixel at a time.\n",
        "\n",
        "#### [22] Grab One Image from the Dataset\n",
        "\n",
        "```python\n",
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "  break\n",
        "```\n",
        "\n",
        "- **What it does:** This code iterates over the dataset and breaks after getting the first image.\n",
        "- **Why it's used:** We want to grab a single image to see what it looks like and to check its shape.\n",
        "\n",
        "#### [24] Check Image Shape\n",
        "\n",
        "```python\n",
        "X_train.shape\n",
        "```\n",
        "\n",
        "- **What it does:** This line returns the shape of the image tensor.\n",
        "- **Output:** For an MNIST image, this would be `[1, 28, 28]`, meaning 1 channel (grayscale), and 28x28 pixels in height and width.\n",
        "\n",
        "#### [25] Reshape the Image\n",
        "\n",
        "```python\n",
        "x = X_train.view(1, 1, 28, 28)\n",
        "```\n",
        "\n",
        "- **What it does:** This reshapes the image to add an additional dimension, making it ready for the convolutional layer.\n",
        "- **Parameters:**\n",
        "  - `1, 1, 28, 28`: The shape of the tensor. The first `1` is the batch size, and the second `1` is the number of channels. The last two numbers are the height and width.\n",
        "\n",
        "#### [26] Perform the First Convolution\n",
        "\n",
        "```python\n",
        "x = F.relu(conv1(x))\n",
        "```\n",
        "\n",
        "- **What it does:** Applies the first convolutional layer followed by a ReLU activation function.\n",
        "- **Why ReLU:** ReLU (Rectified Linear Unit) introduces non-linearity to the model, allowing it to learn more complex patterns.\n",
        "\n",
        "#### [27] Check Shape After Convolution\n",
        "\n",
        "```python\n",
        "x.shape\n",
        "```\n",
        "\n",
        "- **Output:** The shape is `[1, 6, 26, 26]`. The height and width reduce to 26x26 because the 3x3 filter reduces the image size by 2 pixels in each dimension.\n",
        "\n",
        "#### [29] Apply Max Pooling\n",
        "\n",
        "```python\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "```\n",
        "\n",
        "- **What it does:** Applies a max pooling operation, which reduces the size of the image by taking the maximum value in each 2x2 region.\n",
        "- **Parameters:**\n",
        "  - `2, 2`: The size of the pooling filter and the stride. This reduces the image size by half.\n",
        "\n",
        "#### [30] Check Shape After Pooling\n",
        "\n",
        "```python\n",
        "x.shape\n",
        "```\n",
        "\n",
        "- **Output:** The shape is `[1, 6, 13, 13]`, as the pooling operation reduces the dimensions by half.\n",
        "\n",
        "#### [31] Perform the Second Convolution\n",
        "\n",
        "```python\n",
        "x = F.relu(conv2(x))\n",
        "```\n",
        "\n",
        "- **What it does:** Applies the second convolutional layer followed by ReLU activation.\n",
        "- **Shape Reduction:** The output shape after this operation becomes `[1, 16, 11, 11]` because the filter reduces the dimensions further.\n",
        "\n",
        "#### [33] Apply Second Max Pooling\n",
        "\n",
        "```python\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "```\n",
        "\n",
        "- **What it does:** Applies another max pooling operation to further reduce the size of the image.\n",
        "\n",
        "#### [35] Check Final Shape\n",
        "\n",
        "```python\n",
        "x.shape\n",
        "```\n",
        "\n",
        "- **Output:** The final shape is `[1, 16, 5, 5]`, after all the convolution and pooling operations.\n",
        "\n",
        "#### [40] Model Class\n",
        "\n",
        "```python\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "```\n",
        "\n",
        "- **What it does:** Defines a convolutional neural network (CNN) class with two convolutional layers.\n",
        "- **Why Classes:** In PyTorch, models are usually defined as classes to organize layers and operations in a clean way.\n",
        "\n",
        "#### [41] Create Model Instance\n",
        "\n",
        "```python\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "```\n",
        "\n",
        "- **What it does:** Creates an instance of the model and sets a random seed for reproducibility.\n",
        "- **Why Seed:** Setting a seed ensures that the results are reproducible, meaning you'll get the same results every time you run the code.\n",
        "\n",
        "#### [42] Loss Function and Optimizer\n",
        "\n",
        "```python\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "```\n",
        "\n",
        "- **What it does:** Defines the loss function and the optimizer.\n",
        "- **Parameters:**\n",
        "  - `nn.CrossEntropyLoss()`: The loss function used for classification tasks, comparing the model's output with the true labels.\n",
        "  - `torch.optim.Adam`: An optimizer that adjusts the model parameters to minimize the loss function.\n",
        "  - `lr=0.001`: The learning rate, which controls how much to adjust the model parameters with each update. A smaller learning rate means more gradual learning.\n",
        "\n",
        "### Summary\n",
        "This code builds a basic Convolutional Neural Network (CNN) for the MNIST dataset. It includes data loading, model definition, and preparation for training by setting up the loss function and optimizer. Each step transforms the images and their dimensions, leading to the final structure that the model uses to make predictions."
      ],
      "metadata": {
        "id": "R6vkiRHQZNdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAIN AND TEST CNN MODEL - VIDEO 17**"
      ],
      "metadata": {
        "id": "fsrpaijqZPJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create Variables To Tracks Things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "train_correct = []\n",
        "test_losses = []\n",
        "test_correct = []\n",
        "\n",
        "# For loop of Epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "\n",
        "  # Train\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    b +=1  # start our batches at 1\n",
        "    y_pred = model(X_train)  # get predicted values from the training set.Not FLATTENED ITS 2d\n",
        "    print(y_pred)\n",
        "    loss = criterion(y_pred, y_train)  # compare the predicted\n",
        "\n",
        "\n",
        "    predicted = torch.max(y_pred.data, 1)[1] # add up the number of correct predictions.\n",
        "    batch_corr = (predicted == y_train).sum() # how many we got correct from this batch.\n",
        "    trn_corr += batch_corr  # keep track as we go along in training\n",
        "    # Update our parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out some results\n",
        "    if b%600 == 0:\n",
        "      print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "  # Test\n",
        "\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "total = current_time - start_time\n",
        "print(f\"Training Took: {total/60} minutes!\")"
      ],
      "metadata": {
        "id": "5v8OrC1IZjbI",
        "outputId": "d8d2fe04-eeef-4142-bb17-30ff38daa7de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1724419833.9779313"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}